#!/usr/bin/env python3
"""
üêï ENTRENADOR BINARIO AVANZADO
===============================
- M√©tricas completas (Accuracy, Precision, Recall, F1-Score, AUC)
- Control manual despu√©s de cada √©poca
- Visualizaci√≥n detallada del progreso
- Guardado autom√°tico del mejor modelo
"""

import os
import sys
import time
import json
import threading
from datetime import datetime
from pathlib import Path

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from tqdm import tqdm

class EnhancedController:
    """Controlador mejorado para parar entrenamiento despu√©s de cada √©poca"""
    
    def __init__(self):
        self.should_stop = False
        self.input_thread = None
        self.epoch_complete = False
    
    def start_monitoring(self):
        """Iniciar monitoreo de entrada"""
        self.input_thread = threading.Thread(target=self._monitor_input, daemon=True)
        self.input_thread.start()
    
    def _monitor_input(self):
        """Monitor de entrada en hilo separado"""
        while not self.should_stop:
            try:
                if self.epoch_complete:
                    print("\n" + "="*80)
                    print("üõë √âPOCA COMPLETADA - ¬øContinuar entrenamiento?")
                    print("   ‚úÖ Presiona ENTER para continuar")
                    print("   ‚ùå Escribe 'q' + ENTER para parar")
                    print("="*80)
                    
                    user_input = input(">>> ").strip().lower()
                    if user_input == 'q':
                        print("üõë Deteniendo entrenamiento por solicitud del usuario...")
                        self.should_stop = True
                    else:
                        print("‚ñ∂Ô∏è Continuando con la siguiente √©poca...")
                    
                    self.epoch_complete = False
                
                time.sleep(0.1)
            except (EOFError, KeyboardInterrupt):
                self.should_stop = True
                break
    
    def epoch_finished(self):
        """Marcar √©poca como completada"""
        self.epoch_complete = True
    
    def should_continue(self):
        """Verificar si debe continuar"""
        return not self.should_stop

class EnhancedBinaryDataset(Dataset):
    """Dataset binario optimizado para carga r√°pida"""
    
    def __init__(self, data_dir, split='train', transform=None):
        self.data_dir = Path(data_dir)
        self.split = split
        self.transform = transform
        
        # Cargar paths y labels
        self.samples = []
        self.labels = []
        
        # Clase 0: NO-PERRO (nodog)
        no_dog_dir = self.data_dir / split / "nodog"
        if no_dog_dir.exists():
            for img_path in no_dog_dir.rglob("*"):
                if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                    self.samples.append(str(img_path))
                    self.labels.append(0)
        
        # Clase 1: PERRO (dog)
        dog_dir = self.data_dir / split / "dog"
        if dog_dir.exists():
            for img_path in dog_dir.rglob("*"):
                if img_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                    self.samples.append(str(img_path))
                    self.labels.append(1)
        
        print(f"üìä Dataset {split}: {len(self.samples)} muestras")
        print(f"   ‚ùå NO-PERRO: {sum(1 for l in self.labels if l == 0):,}")
        print(f"   ‚úÖ PERRO: {sum(1 for l in self.labels if l == 1):,}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        img_path = self.samples[idx]
        label = self.labels[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label
        except Exception as e:
            # Retornar imagen negra en caso de error
            if self.transform:
                return self.transform(Image.new('RGB', (224, 224))), label
            return Image.new('RGB', (224, 224)), label

class EnhancedBinaryModel(nn.Module):
    """Modelo binario con ResNet18 y m√©tricas avanzadas"""
    
    def __init__(self, num_classes=2):
        super().__init__()
        self.backbone = models.resnet18(weights='DEFAULT')
        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)
        
    def forward(self, x):
        return self.backbone(x)

def calculate_metrics(y_true, y_pred, y_scores):
    """Calcular m√©tricas completas"""
    metrics = {}
    
    # M√©tricas b√°sicas
    metrics['accuracy'] = accuracy_score(y_true, y_pred)
    metrics['precision'] = precision_score(y_true, y_pred, average='weighted', zero_division=0)
    metrics['recall'] = recall_score(y_true, y_pred, average='weighted', zero_division=0)
    metrics['f1'] = f1_score(y_true, y_pred, average='weighted', zero_division=0)
    
    # AUC (solo para clasificaci√≥n binaria)
    if len(np.unique(y_true)) == 2:
        metrics['auc'] = roc_auc_score(y_true, y_scores[:, 1])
    
    # Matriz de confusi√≥n
    cm = confusion_matrix(y_true, y_pred)
    metrics['confusion_matrix'] = cm
    
    if len(cm) == 2:
        tn, fp, fn, tp = cm.ravel()
        metrics['true_negatives'] = int(tn)
        metrics['false_positives'] = int(fp)
        metrics['false_negatives'] = int(fn)
        metrics['true_positives'] = int(tp)
        
        # M√©tricas adicionales
        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0
        metrics['sensitivity'] = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    return metrics

def print_metrics(metrics, split_name=""):
    """Imprimir m√©tricas de forma bonita"""
    print(f"\nüìä M√âTRICAS {split_name.upper()}")
    print("="*60)
    print(f"üéØ Accuracy:   {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
    print(f"üéØ Precision:  {metrics['precision']:.4f}")
    print(f"üéØ Recall:     {metrics['recall']:.4f}")
    print(f"üéØ F1-Score:   {metrics['f1']:.4f}")
    
    if 'auc' in metrics:
        print(f"üìà AUC:        {metrics['auc']:.4f}")
    
    if 'specificity' in metrics and 'sensitivity' in metrics:
        print(f"üîç Specificity: {metrics['specificity']:.4f}")
        print(f"üîç Sensitivity: {metrics['sensitivity']:.4f}")
    
    if 'confusion_matrix' in metrics:
        cm = metrics['confusion_matrix']
        print(f"\nüìã MATRIZ DE CONFUSI√ìN:")
        print(f"    Pred:  [NO-PERRO] [PERRO]")
        print(f"Real NO-PERRO:  {cm[0,0]:6d}   {cm[0,1]:6d}")
        print(f"Real PERRO:     {cm[1,0]:6d}   {cm[1,1]:6d}")

def evaluate_model(model, dataloader, device):
    """Evaluar modelo con m√©tricas completas"""
    model.eval()
    all_predictions = []
    all_labels = []
    all_scores = []
    
    with torch.no_grad():
        for inputs, labels in tqdm(dataloader, desc="Evaluando", leave=False):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            scores = torch.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_scores.extend(scores.cpu().numpy())
    
    return calculate_metrics(all_labels, all_predictions, np.array(all_scores))

def save_training_log(log_data, log_path):
    """Guardar log de entrenamiento"""
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False, default=str)

def main():
    print("üêï ENTRENADOR BINARIO AVANZADO")
    print("üöÄ Con m√©tricas completas y control por √©poca")
    print("="*80)
    
    # Configuraci√≥n
    DATA_DIR = "processed_data"
    BATCH_SIZE = 16
    EPOCHS = 20
    LEARNING_RATE = 0.001
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üíª Dispositivo: {device}")
    
    # Crear directorio para modelos
    os.makedirs("enhanced_binary_models", exist_ok=True)
    
    # Transformaciones optimizadas
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                           std=[0.229, 0.224, 0.225])
    ])
    
    # Crear datasets
    print("üìä Creando datasets...")
    train_dataset = EnhancedBinaryDataset(DATA_DIR, 'train', train_transform)
    val_dataset = EnhancedBinaryDataset(DATA_DIR, 'val', val_transform)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    
    # Crear modelo
    print("ü§ñ Creando modelo ResNet18...")
    model = EnhancedBinaryModel().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
    
    # Controlador mejorado
    controller = EnhancedController()
    controller.start_monitoring()
    
    print("\nüöÄ ENTRENAMIENTO BINARIO AVANZADO")
    print("="*80)
    print(f"üéØ √âpocas: {EPOCHS}")
    print(f"üîÑ Batch Size: {BATCH_SIZE}")
    print(f"üìö Learning Rate: {LEARNING_RATE}")
    print(f"üíª Dispositivo: {device}")
    print("‚ö†Ô∏è El sistema te preguntar√° despu√©s de cada √©poca si continuar")
    
    # Variables para tracking
    best_val_acc = 0
    training_log = {
        'start_time': datetime.now().isoformat(),
        'config': {
            'epochs': EPOCHS,
            'batch_size': BATCH_SIZE,
            'learning_rate': LEARNING_RATE,
            'device': str(device)
        },
        'epochs': []
    }
    
    for epoch in range(EPOCHS):
        if not controller.should_continue():
            print("üõë Entrenamiento detenido por el usuario")
            break
            
        print(f"\nüìÖ √âPOCA {epoch + 1}/{EPOCHS}")
        print("-" * 60)
        
        # ENTRENAMIENTO
        model.train()
        train_loss = 0
        train_predictions = []
        train_labels = []
        train_scores = []
        
        progress_bar = tqdm(train_loader, desc=f"√âpoca {epoch+1}")
        
        for batch_idx, (inputs, labels) in enumerate(progress_bar):
            if not controller.should_continue():
                break
                
            inputs, labels = inputs.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            
            # Recopilar predicciones para m√©tricas
            scores = torch.softmax(outputs, dim=1)
            _, predicted = torch.max(outputs.data, 1)
            
            train_predictions.extend(predicted.cpu().numpy())
            train_labels.extend(labels.cpu().numpy())
            train_scores.extend(scores.detach().cpu().numpy())
            
            # Actualizar barra de progreso
            current_acc = accuracy_score(train_labels[-len(labels):], 
                                       train_predictions[-len(labels):])
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Acc': f'{current_acc:.4f}'
            })
        
        if not controller.should_continue():
            break
            
        # Calcular m√©tricas de entrenamiento
        train_metrics = calculate_metrics(train_labels, train_predictions, np.array(train_scores))
        avg_train_loss = train_loss / len(train_loader)
        
        # VALIDACI√ìN
        print("\nüîç Evaluando en validaci√≥n...")
        val_metrics = evaluate_model(model, val_loader, device)
        
        # Actualizar scheduler
        scheduler.step()
        
        # Imprimir resultados
        print(f"\nüèÉ RESULTADOS √âPOCA {epoch + 1}")
        print("="*60)
        print(f"üìâ Train Loss: {avg_train_loss:.4f}")
        print_metrics(train_metrics, "TRAIN")
        print_metrics(val_metrics, "VALIDACI√ìN")
        
        # Guardar mejor modelo
        if val_metrics['accuracy'] > best_val_acc:
            best_val_acc = val_metrics['accuracy']
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_acc': best_val_acc,
                'train_metrics': train_metrics,
                'val_metrics': val_metrics
            }, f"enhanced_binary_models/best_model_epoch_{epoch+1}_acc_{val_metrics['accuracy']:.4f}.pth")
            print(f"üíæ Mejor modelo guardado! (Acc: {best_val_acc:.4f})")
        
        # Guardar log
        epoch_data = {
            'epoch': epoch + 1,
            'train_loss': avg_train_loss,
            'train_metrics': train_metrics,
            'val_metrics': val_metrics,
            'learning_rate': scheduler.get_last_lr()[0],
            'timestamp': datetime.now().isoformat()
        }
        training_log['epochs'].append(epoch_data)
        
        # Marcar √©poca completada y esperar decisi√≥n del usuario
        controller.epoch_finished()
        
        # Esperar hasta que el usuario decida
        while controller.epoch_complete and controller.should_continue():
            time.sleep(0.1)
    
    # Finalizar entrenamiento
    training_log['end_time'] = datetime.now().isoformat()
    training_log['best_val_accuracy'] = float(best_val_acc)
    
    log_path = f"enhanced_binary_models/training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    save_training_log(training_log, log_path)
    
    print(f"\nüéâ ENTRENAMIENTO FINALIZADO")
    print("="*60)
    print(f"üèÜ Mejor accuracy de validaci√≥n: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)")
    print(f"üìÑ Log guardado en: {log_path}")
    print("‚úÖ Todos los modelos guardados en: enhanced_binary_models/")

if __name__ == "__main__":
    main()