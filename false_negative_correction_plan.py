#!/usr/bin/env python3
"""
ğŸ› ï¸ PLAN DE CORRECCIÃ“N PARA FALSOS NEGATIVOS
==========================================
Estrategias prÃ¡cticas para reducir falsos negativos en razas problemÃ¡ticas
del modelo de 119 clases
"""

import json
import torch
import torch.nn as nn
import numpy as np
from pathlib import Path

class FalseNegativeCorrector:
    def __init__(self):
        self.problematic_breeds = {
            'critical': ['Lhasa', 'cairn'],
            'high_priority': ['Siberian_husky', 'whippet', 'malamute', 'Australian_terrier', 
                            'Norfolk_terrier', 'toy_terrier', 'Italian_greyhound'],
            'medium_priority': ['Lakeland_terrier', 'Border_terrier', 'bluetick', 
                              'Rhodesian_ridgeback', 'Ibizan_hound']
        }
        
    def generate_correction_plan(self):
        """Generar plan completo de correcciÃ³n"""
        print("ğŸ› ï¸ PLAN DE CORRECCIÃ“N PARA FALSOS NEGATIVOS")
        print("=" * 60)
        
        correction_strategies = {
            "1_threshold_adjustment": self.threshold_adjustment_strategy(),
            "2_weighted_loss": self.weighted_loss_strategy(), 
            "3_data_augmentation": self.data_augmentation_strategy(),
            "4_focal_loss": self.focal_loss_strategy(),
            "5_ensemble_methods": self.ensemble_strategy(),
            "6_hard_negative_mining": self.hard_negative_mining_strategy(),
            "7_class_balancing": self.class_balancing_strategy(),
            "8_feature_enhancement": self.feature_enhancement_strategy()
        }
        
        return correction_strategies
    
    def threshold_adjustment_strategy(self):
        """Estrategia 1: Ajuste de umbrales por clase"""
        print("\nğŸ“ˆ ESTRATEGIA 1: AJUSTE DE UMBRALES POR CLASE")
        print("-" * 50)
        print("ğŸ¯ Objetivo: Reducir umbrales para razas conservadoras")
        
        strategy = {
            "description": "Usar umbrales adaptativos mÃ¡s bajos para razas con muchos falsos negativos",
            "implementation": """
# Umbrales personalizados por raza (mÃ¡s bajos = menos conservador)
BREED_THRESHOLDS = {
    'Lhasa': 0.35,           # Muy bajo (era conservador)
    'cairn': 0.40,           # Bajo (era muy conservador)  
    'Siberian_husky': 0.45,  # Bajo-medio
    'whippet': 0.45,         # Bajo-medio
    'malamute': 0.50,        # Medio
    'Australian_terrier': 0.50,
    'Norfolk_terrier': 0.50,
    'toy_terrier': 0.55,     # Medio-alto (tenÃ­a buena precision)
    # Razas normales usan threshold estÃ¡ndar = 0.60
}

def apply_adaptive_thresholds(predictions, breed_names, default_threshold=0.60):
    adjusted_predictions = []
    
    for i, breed in enumerate(breed_names):
        threshold = BREED_THRESHOLDS.get(breed, default_threshold)
        pred_score = predictions[i]
        
        # Aplicar threshold personalizado
        if pred_score >= threshold:
            adjusted_predictions.append((breed, pred_score, True))
        else:
            adjusted_predictions.append((breed, pred_score, False))
    
    return adjusted_predictions
            """,
            "expected_improvement": "15-25% reducciÃ³n en falsos negativos para razas crÃ­ticas",
            "risk_level": "BAJO - fÃ¡cil de implementar y revertir"
        }
        
        print("âœ… ImplementaciÃ³n INMEDIATA recomendada")
        print("ğŸ“Š Mejora esperada: 15-25% menos falsos negativos")
        
        return strategy
    
    def weighted_loss_strategy(self):
        """Estrategia 2: FunciÃ³n de pÃ©rdida ponderada"""
        print("\nğŸ¯ ESTRATEGIA 2: WEIGHTED LOSS FUNCTION")
        print("-" * 50)
        print("ğŸ¯ Objetivo: Penalizar mÃ¡s los falsos negativos que los falsos positivos")
        
        strategy = {
            "description": "Usar pesos de clase que penalicen mÃ¡s los falsos negativos en razas problemÃ¡ticas",
            "implementation": """
import torch.nn as nn

class WeightedFocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2, recall_weight=2.0):
        super().__init__()
        self.alpha = alpha  # Pesos por clase
        self.gamma = gamma  # Factor focal
        self.recall_weight = recall_weight  # PenalizaciÃ³n extra para FN
        
    def forward(self, inputs, targets):
        ce_loss = nn.CrossEntropyLoss(weight=self.alpha)(inputs, targets)
        pt = torch.exp(-ce_loss)
        
        # Focal loss component
        focal_loss = (1 - pt) ** self.gamma * ce_loss
        
        # Extra penalty for false negatives
        # Detectar predicciones incorrectas
        pred_classes = torch.argmax(inputs, dim=1)
        false_negatives = (pred_classes != targets)
        
        # Aplicar penalizaciÃ³n extra a falsos negativos
        penalty = torch.where(false_negatives, 
                            torch.tensor(self.recall_weight), 
                            torch.tensor(1.0)).to(inputs.device)
        
        return (focal_loss * penalty).mean()

# Pesos especÃ­ficos para razas problemÃ¡ticas
CLASS_WEIGHTS = {
    'Lhasa': 3.0,           # Triple peso (tenÃ­a 46% FN)
    'cairn': 2.8,           # Alto peso (tenÃ­a 41% FN)
    'Siberian_husky': 2.5,  # Alto peso
    'whippet': 2.3,         # Alto peso
    'malamute': 2.2,        # Medio-alto peso
    # Razas normales = 1.0
}

def create_class_weights(num_classes, problematic_breeds_weights):
    weights = torch.ones(num_classes)
    
    for breed_idx, breed_name in enumerate(breed_names):
        if breed_name in problematic_breeds_weights:
            weights[breed_idx] = problematic_breeds_weights[breed_name]
    
    return weights
            """,
            "expected_improvement": "20-35% reducciÃ³n en falsos negativos",
            "risk_level": "MEDIO - requiere reentrenamiento"
        }
        
        print("âš¡ ImplementaciÃ³n: Requiere reentrenamiento del modelo")
        print("ğŸ“Š Mejora esperada: 20-35% menos falsos negativos")
        
        return strategy
    
    def data_augmentation_strategy(self):
        """Estrategia 3: AugmentaciÃ³n de datos especializada"""
        print("\nğŸ”„ ESTRATEGIA 3: AUGMENTACIÃ“N ESPECIALIZADA")
        print("-" * 50)
        print("ğŸ¯ Objetivo: MÃ¡s variedad de datos para razas problemÃ¡ticas")
        
        strategy = {
            "description": "AugmentaciÃ³n especÃ­fica segÃºn el tipo de raza y sus problemas",
            "implementation": """
import torchvision.transforms as transforms
from torchvision.transforms import RandomAffine, ColorJitter, RandomHorizontalFlip

# AugmentaciÃ³n especÃ­fica por grupo de razas
BREED_SPECIFIC_AUGMENTATION = {
    # Para terriers pequeÃ±os (caracterÃ­sticas sutiles)
    'terriers': transforms.Compose([
        transforms.RandomRotation(15),  # VariaciÃ³n de Ã¡ngulo
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Zoom variado
        transforms.ColorJitter(brightness=0.3, contrast=0.3),  # IluminaciÃ³n
        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),  # PosiciÃ³n
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),  # Enfoque variado
    ]),
    
    # Para perros nÃ³rdicos (diferencias de tamaÃ±o/pelaje)
    'nordic': transforms.Compose([
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),  # MÃ¡s variaciÃ³n de escala
        transforms.ColorJitter(brightness=0.4, saturation=0.3),  # Pelaje variado
        transforms.RandomPerspective(distortion_scale=0.2),  # Perspectiva
        transforms.RandomErasing(p=0.3, scale=(0.02, 0.1)),  # OclusiÃ³n parcial
    ]),
    
    # Para galgos/lebreles (proporciones corporales)
    'sighthounds': transforms.Compose([
        transforms.RandomAffine(degrees=20, translate=(0.15, 0.15)),
        transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),  # Cuerpo completo
        transforms.ColorJitter(contrast=0.4),  # DefiniciÃ³n muscular
        transforms.RandomRotation(25),  # Ãngulos variados
    ])
}

def apply_breed_specific_augmentation(image, breed_name):
    \"\"\"Aplicar augmentaciÃ³n especÃ­fica segÃºn la raza\"\"\"
    
    # Clasificar raza en grupo
    if breed_name in ['cairn', 'Norfolk_terrier', 'toy_terrier', 'Australian_terrier']:
        augmentation = BREED_SPECIFIC_AUGMENTATION['terriers']
    elif breed_name in ['Siberian_husky', 'malamute']:
        augmentation = BREED_SPECIFIC_AUGMENTATION['nordic'] 
    elif breed_name in ['whippet', 'Italian_greyhound']:
        augmentation = BREED_SPECIFIC_AUGMENTATION['sighthounds']
    else:
        # AugmentaciÃ³n estÃ¡ndar
        augmentation = transforms.Compose([
            transforms.RandomRotation(10),
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.ColorJitter(brightness=0.2, contrast=0.2)
        ])
    
    return augmentation(image)

# Generar mÃ¡s datos para razas crÃ­ticas
AUGMENTATION_MULTIPLIER = {
    'Lhasa': 4,           # 4x mÃ¡s datos
    'cairn': 4,           # 4x mÃ¡s datos  
    'Siberian_husky': 3,  # 3x mÃ¡s datos
    'whippet': 3,         # 3x mÃ¡s datos
    'malamute': 3,        # 3x mÃ¡s datos
    # Razas normales = 1x
}
            """,
            "expected_improvement": "10-20% reducciÃ³n en falsos negativos",
            "risk_level": "BAJO - no afecta modelo actual"
        }
        
        print("ğŸ“¸ ImplementaciÃ³n: Generar mÃ¡s datos variados")
        print("ğŸ“Š Mejora esperada: 10-20% menos falsos negativos")
        
        return strategy
    
    def focal_loss_strategy(self):
        """Estrategia 4: Focal Loss para clases difÃ­ciles"""
        print("\nğŸ§  ESTRATEGIA 4: FOCAL LOSS IMPLEMENTATION")
        print("-" * 50)
        print("ğŸ¯ Objetivo: Enfocarse en ejemplos difÃ­ciles de clasificar")
        
        strategy = {
            "description": "Usar Focal Loss para dar mÃ¡s importancia a ejemplos difÃ­ciles",
            "implementation": """
class AdaptiveFocalLoss(nn.Module):
    def __init__(self, alpha=1, gamma=2, breed_specific_gamma=None):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.breed_specific_gamma = breed_specific_gamma or {}
        
    def forward(self, inputs, targets, breed_names=None):
        ce_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)
        pt = torch.exp(-ce_loss)
        
        # Gamma especÃ­fico por raza si se proporciona
        if breed_names is not None and self.breed_specific_gamma:
            gamma_values = torch.ones_like(targets, dtype=torch.float)
            for i, breed in enumerate(breed_names):
                if breed in self.breed_specific_gamma:
                    gamma_values[i] = self.breed_specific_gamma[breed]
        else:
            gamma_values = self.gamma
            
        focal_loss = self.alpha * (1 - pt) ** gamma_values * ce_loss
        return focal_loss.mean()

# Gamma especÃ­fico para razas problemÃ¡ticas (mÃ¡s alto = mÃ¡s enfoque)
BREED_SPECIFIC_GAMMA = {
    'Lhasa': 3.0,           # Muy alto enfoque
    'cairn': 2.8,           # Alto enfoque
    'Siberian_husky': 2.5,  # Alto enfoque
    'whippet': 2.3,         # Medio-alto enfoque
    'malamute': 2.2,        # Medio-alto enfoque
    # Razas normales = 2.0 (gamma estÃ¡ndar)
}

# IntegraciÃ³n en el entrenamiento
def train_with_adaptive_focal_loss(model, train_loader, device):
    criterion = AdaptiveFocalLoss(
        alpha=1, 
        gamma=2.0, 
        breed_specific_gamma=BREED_SPECIFIC_GAMMA
    )
    
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    model.train()
    for batch_idx, (data, targets, breed_names) in enumerate(train_loader):
        data, targets = data.to(device), targets.to(device)
        
        optimizer.zero_grad()
        outputs = model(data)
        
        # Usar focal loss adaptativo
        loss = criterion(outputs, targets, breed_names)
        loss.backward()
        optimizer.step()
            """,
            "expected_improvement": "25-30% reducciÃ³n en falsos negativos",
            "risk_level": "MEDIO - requiere reentrenamiento completo"
        }
        
        print("ğŸ¯ ImplementaciÃ³n: Focal Loss con gamma adaptativo")
        print("ğŸ“Š Mejora esperada: 25-30% menos falsos negativos")
        
        return strategy
    
    def ensemble_strategy(self):
        """Estrategia 5: MÃ©todos de ensemble"""
        print("\nğŸ“Š ESTRATEGIA 5: ENSEMBLE METHODS")
        print("-" * 50)
        print("ğŸ¯ Objetivo: Combinar mÃºltiples modelos para mejor recall")
        
        strategy = {
            "description": "Usar ensemble de modelos optimizados para diferentes aspectos",
            "implementation": """
class RecallOptimizedEnsemble:
    def __init__(self, models, weights=None):
        self.models = models
        self.weights = weights or [1.0] * len(models)
        
    def predict(self, x):
        predictions = []
        
        for i, model in enumerate(self.models):
            model.eval()
            with torch.no_grad():
                pred = torch.softmax(model(x), dim=1)
                predictions.append(pred * self.weights[i])
        
        # Promedio ponderado
        ensemble_pred = torch.stack(predictions).mean(dim=0)
        return ensemble_pred
    
    def predict_with_recall_boost(self, x, breed_name, recall_boost_factor=1.2):
        base_prediction = self.predict(x)
        
        # Boost para razas con problemas de recall
        if breed_name in ['Lhasa', 'cairn', 'Siberian_husky', 'whippet']:
            # Incrementar probabilidad de la clase correcta
            class_idx = get_breed_index(breed_name)
            base_prediction[:, class_idx] *= recall_boost_factor
            
            # Renormalizar
            base_prediction = torch.softmax(base_prediction, dim=1)
        
        return base_prediction

# Crear ensemble especializado
def create_recall_optimized_ensemble():
    # Modelo 1: Optimizado para precisiÃ³n general
    model1 = load_model('best_model_fold_0.pth')
    
    # Modelo 2: Entrenado con focal loss
    model2 = load_model('focal_loss_model.pth')
    
    # Modelo 3: Entrenado con weighted loss
    model3 = load_model('weighted_model.pth')
    
    # Pesos del ensemble (mÃ¡s peso a modelos optimizados para recall)
    ensemble_weights = [0.3, 0.4, 0.3]  # MÃ¡s peso al focal loss
    
    return RecallOptimizedEnsemble([model1, model2, model3], ensemble_weights)

# Uso en producciÃ³n
ensemble = create_recall_optimized_ensemble()
prediction = ensemble.predict_with_recall_boost(image, breed_name)
            """,
            "expected_improvement": "30-40% reducciÃ³n en falsos negativos",
            "risk_level": "ALTO - requiere mÃºltiples modelos"
        }
        
        print("ğŸ”„ ImplementaciÃ³n: Ensemble de 3 modelos especializados")
        print("ğŸ“Š Mejora esperada: 30-40% menos falsos negativos")
        
        return strategy
    
    def generate_implementation_roadmap(self):
        """Generar roadmap de implementaciÃ³n"""
        print("\n" + "=" * 70)
        print("ğŸ—ºï¸ ROADMAP DE IMPLEMENTACIÃ“N - CORRECCIÃ“N DE FALSOS NEGATIVOS")
        print("=" * 70)
        
        roadmap = {
            "Phase_1_Immediate": {
                "timeframe": "1-2 dÃ­as",
                "actions": [
                    "âœ… Implementar ajuste de umbrales por clase",
                    "âœ… Aplicar umbrales mÃ¡s bajos a razas crÃ­ticas",
                    "âœ… Testing inmediato en razas problemÃ¡ticas"
                ],
                "expected_improvement": "15-25%",
                "effort": "BAJO"
            },
            "Phase_2_Short_term": {
                "timeframe": "1 semana", 
                "actions": [
                    "ğŸ”„ Implementar augmentaciÃ³n especializada",
                    "ğŸ“¸ Generar mÃ¡s datos para razas crÃ­ticas",
                    "ğŸ§ª Testing con nuevos datos"
                ],
                "expected_improvement": "25-35%",
                "effort": "MEDIO"
            },
            "Phase_3_Medium_term": {
                "timeframe": "2-3 semanas",
                "actions": [
                    "ğŸ¯ Implementar Weighted/Focal Loss",
                    "ğŸ”„ Reentrenar modelo con nuevas funciones de pÃ©rdida",
                    "ğŸ“Š ValidaciÃ³n completa del modelo"
                ],
                "expected_improvement": "35-50%",
                "effort": "ALTO"
            },
            "Phase_4_Long_term": {
                "timeframe": "1 mes",
                "actions": [
                    "ğŸ“Š Implementar ensemble methods",
                    "ğŸ”§ OptimizaciÃ³n completa del pipeline",
                    "ğŸš€ Despliegue en producciÃ³n"
                ],
                "expected_improvement": "50-60%",
                "effort": "MUY ALTO"
            }
        }
        
        for phase, details in roadmap.items():
            print(f"\nğŸ¯ {phase.replace('_', ' ').upper()}")
            print(f"   â±ï¸  Tiempo: {details['timeframe']}")
            print(f"   ğŸ“ˆ Mejora esperada: {details['expected_improvement']}")
            print(f"   ğŸ’ª Esfuerzo: {details['effort']}")
            print("   ğŸ“‹ Acciones:")
            for action in details['actions']:
                print(f"      {action}")
        
        return roadmap
    
    def create_quick_fix_script(self):
        """Crear script de correcciÃ³n rÃ¡pida (Fase 1)"""
        print("\n" + "=" * 60)
        print("âš¡ SCRIPT DE CORRECCIÃ“N RÃPIDA - LISTO PARA USAR")
        print("=" * 60)
        
        quick_fix_code = '''
# ğŸš€ CORRECCIÃ“N INMEDIATA - AJUSTE DE UMBRALES
# Archivo: quick_false_negative_fix.py

import torch
import numpy as np

class ThresholdOptimizedClassifier:
    def __init__(self, base_model, breed_thresholds=None):
        self.base_model = base_model
        self.breed_thresholds = breed_thresholds or {
            'Lhasa': 0.35,           # Muy bajo (era 46% FN)
            'cairn': 0.40,           # Bajo (era 41% FN)
            'Siberian_husky': 0.45,  # Bajo-medio (era 38% FN)
            'whippet': 0.45,         # Bajo-medio (era 36% FN)
            'malamute': 0.50,        # Medio (era 35% FN)
            'Australian_terrier': 0.50,
            'Norfolk_terrier': 0.50,
            'toy_terrier': 0.55,
            'Italian_greyhound': 0.55,
        }
        self.default_threshold = 0.60
        
    def predict_with_adaptive_thresholds(self, image, breed_names):
        # Obtener predicciones del modelo base
        with torch.no_grad():
            logits = self.base_model(image)
            probabilities = torch.softmax(logits, dim=1)
        
        results = []
        
        for i, breed in enumerate(breed_names):
            prob_score = probabilities[0][i].item()
            threshold = self.breed_thresholds.get(breed, self.default_threshold)
            
            # Aplicar threshold adaptativo
            is_predicted = prob_score >= threshold
            
            results.append({
                'breed': breed,
                'probability': prob_score,
                'threshold_used': threshold,
                'predicted': is_predicted,
                'improvement': 'OPTIMIZED' if breed in self.breed_thresholds else 'STANDARD'
            })
        
        return sorted(results, key=lambda x: x['probability'], reverse=True)

# USO INMEDIATO:
# 1. Cargar tu modelo actual
# model = torch.load('best_model_fold_0.pth')
# 
# 2. Crear clasificador optimizado
# optimized_classifier = ThresholdOptimizedClassifier(model)
# 
# 3. Usar con imÃ¡genes
# results = optimized_classifier.predict_with_adaptive_thresholds(image, breed_names)
'''
        
        # Guardar script
        with open('quick_false_negative_fix.py', 'w') as f:
            f.write(quick_fix_code)
        
        print("ğŸ’¾ Script guardado como: quick_false_negative_fix.py")
        print("âš¡ LISTO PARA USAR INMEDIATAMENTE!")
        
        return quick_fix_code

def main():
    """Ejecutar anÃ¡lisis completo de correcciÃ³n"""
    print("ğŸ› ï¸ Iniciando Plan de CorrecciÃ³n para Falsos Negativos...")
    
    corrector = FalseNegativeCorrector()
    
    # Generar estrategias
    strategies = corrector.generate_correction_plan()
    
    # Generar roadmap
    roadmap = corrector.generate_implementation_roadmap()
    
    # Crear script de correcciÃ³n rÃ¡pida
    corrector.create_quick_fix_script()
    
    print("\n" + "=" * 70)
    print("âœ… PLAN DE CORRECCIÃ“N COMPLETADO")
    print("=" * 70)
    print("ğŸ¯ PRÃ“XIMOS PASOS RECOMENDADOS:")
    print("   1. âš¡ Usar 'quick_false_negative_fix.py' INMEDIATAMENTE")
    print("   2. ğŸ§ª Probar con razas problemÃ¡ticas (Lhasa, Cairn, Husky)")
    print("   3. ğŸ“Š Medir mejora en recall")
    print("   4. ğŸ”„ Proceder con Fase 2 si los resultados son buenos")
    
    return {
        'strategies': strategies,
        'roadmap': roadmap,
        'quick_fix_ready': True
    }

if __name__ == "__main__":
    main()