#!/usr/bin/env python3
"""
üî¨ AN√ÅLISIS DE NECESIDAD DE REENTRENAMIENTO
==========================================

Eval√∫a qu√© mejoras para reducir sesgos requieren reentrenamiento vs 
ajustes de post-procesamiento. Propone plan de acci√≥n optimizado.

Autor: Sistema IA
Fecha: 2024
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

class RetrainingAnalyzer:
    def __init__(self, workspace_path: str):
        self.workspace_path = Path(workspace_path)
        
        # Cargar resultados de evaluaci√≥n previa
        self.load_previous_results()
    
    def load_previous_results(self):
        """Carga resultados de evaluaciones previas"""
        self.bias_analysis = {}
        self.class_evaluation = {}
        
        # Cargar an√°lisis de sesgos
        bias_file = self.workspace_path / "bias_analysis_report.json"
        if bias_file.exists():
            with open(bias_file, 'r', encoding='utf-8') as f:
                self.bias_analysis = json.load(f)
        
        # Cargar evaluaci√≥n de clases
        class_file = self.workspace_path / "complete_class_evaluation_report.json"
        if class_file.exists():
            with open(class_file, 'r', encoding='utf-8') as f:
                self.class_evaluation = json.load(f)
    
    def analyze_current_performance_gaps(self):
        """Analiza las brechas de rendimiento que podr√≠an requerir reentrenamiento"""
        print("üîç AN√ÅLISIS DE BRECHAS DE RENDIMIENTO ACTUALES")
        print("="*70)
        
        if not self.class_evaluation:
            print("‚ùå No se encontraron resultados de evaluaci√≥n por clase")
            return None
        
        # Analizar clases problem√°ticas
        class_details = self.class_evaluation.get('class_details', {})
        problematic_classes = []
        excellent_classes = []
        
        for breed, details in class_details.items():
            accuracy = details.get('accuracy', 0.0)
            if accuracy < 0.7:
                problematic_classes.append((breed, accuracy))
            elif accuracy > 0.95:
                excellent_classes.append((breed, accuracy))
        
        # Estad√≠sticas actuales
        accuracies = [details['accuracy'] for details in class_details.values()]
        mean_acc = np.mean(accuracies)
        std_acc = np.std(accuracies)
        min_acc = min(accuracies)
        max_acc = max(accuracies)
        
        print(f"üìä ESTAD√çSTICAS DE RENDIMIENTO ACTUAL:")
        print(f"   Accuracy promedio: {mean_acc:.3f}")
        print(f"   Desviaci√≥n est√°ndar: {std_acc:.3f}")
        print(f"   Rango: {min_acc:.3f} - {max_acc:.3f}")
        print(f"   Clases problem√°ticas (<0.70): {len(problematic_classes)}")
        print(f"   Clases excelentes (>0.95): {len(excellent_classes)}")
        
        # Calcular brecha de rendimiento
        performance_gap = max_acc - min_acc
        print(f"   üö® BRECHA DE RENDIMIENTO: {performance_gap:.3f}")
        
        # An√°lisis de necesidad de reentrenamiento
        needs_retraining = self._evaluate_retraining_need(
            mean_acc, std_acc, len(problematic_classes), performance_gap
        )
        
        return {
            'mean_accuracy': mean_acc,
            'std_accuracy': std_acc,
            'performance_gap': performance_gap,
            'problematic_classes': problematic_classes,
            'excellent_classes': excellent_classes,
            'needs_retraining': needs_retraining
        }
    
    def _evaluate_retraining_need(self, mean_acc, std_acc, problematic_count, gap):
        """Eval√∫a si se necesita reentrenamiento basado en m√©tricas"""
        reasons = []
        priority = "LOW"
        
        # Criterios para reentrenamiento
        if std_acc > 0.15:
            reasons.append(f"Alta variabilidad entre clases (std={std_acc:.3f})")
            priority = "MEDIUM"
        
        if gap > 0.4:
            reasons.append(f"Brecha excesiva entre mejor/peor clase ({gap:.3f})")
            priority = "HIGH"
        
        if problematic_count > 8:
            reasons.append(f"Demasiadas clases problem√°ticas ({problematic_count})")
            priority = "HIGH"
        
        if mean_acc < 0.85:
            reasons.append(f"Accuracy promedio baja ({mean_acc:.3f})")
            priority = "MEDIUM"
        
        return {
            'recommended': len(reasons) > 0,
            'priority': priority,
            'reasons': reasons
        }
    
    def categorize_improvement_strategies(self):
        """Categoriza estrategias de mejora por si requieren reentrenamiento o no"""
        print("\nüîß CATEGORIZACI√ìN DE ESTRATEGIAS DE MEJORA")
        print("="*70)
        
        # Mejoras SIN reentrenamiento (ya implementadas)
        no_retraining = {
            "‚úÖ IMPLEMENTADAS SIN REENTRENAMIENTO": [
                "Eliminar modelo selectivo (arquitectura unificada)",
                "Umbrales adaptativos por raza", 
                "M√©tricas detalladas por clase individual",
                "Calibraci√≥n de temperatura optimizada",
                "Evaluaci√≥n estratificada por clase",
                "Sistema de detecci√≥n de sesgos automatizado"
            ]
        }
        
        # Mejoras que S√ç requieren reentrenamiento
        requires_retraining = {
            "üîÑ REQUIEREN REENTRENAMIENTO COMPLETO": [
                "Diversificaci√≥n geogr√°fica del dataset (+ razas asi√°ticas/africanas)",
                "Balanceo de tama√±os f√≠sicos (+ razas grandes)",
                "Data augmentation espec√≠fica para clases problem√°ticas",
                "Arquitectura mejorada (ej. EfficientNet, Vision Transformer)",
                "Transfer learning con modelos m√°s recientes",
                "Entrenamiento multi-tarea (detecci√≥n + clasificaci√≥n)"
            ],
            "üéØ REQUIEREN FINE-TUNING DIRIGIDO": [
                "Reentrenamiento solo de clases problem√°ticas",
                "Ajuste de learning rate por clase",
                "Weighted loss para clases desbalanceadas",
                "Focal loss para clases dif√≠ciles",
                "Class-balanced sampling durante entrenamiento",
                "Mixup/CutMix espec√≠fico para clases problem√°ticas"
            ]
        }
        
        # Mejoras de post-procesamiento
        post_processing = {
            "‚ö° POST-PROCESAMIENTO (SIN REENTRENAMIENTO)": [
                "Ensemble de m√∫ltiples modelos existentes",
                "Test-time augmentation (TTA)",
                "Calibraci√≥n avanzada de probabilidades",
                "Filtros de confianza adaptativos",
                "Voting schemes para predicciones ambiguas",
                "Rejection sampling para predicciones inciertas"
            ]
        }
        
        all_strategies = {**no_retraining, **requires_retraining, **post_processing}
        
        for category, strategies in all_strategies.items():
            print(f"\n{category}:")
            for i, strategy in enumerate(strategies, 1):
                print(f"   {i}. {strategy}")
        
        return all_strategies
    
    def recommend_action_plan(self, performance_analysis):
        """Recomienda plan de acci√≥n basado en el an√°lisis"""
        print(f"\nüéØ RECOMENDACI√ìN DE PLAN DE ACCI√ìN")
        print("="*70)
        
        if not performance_analysis:
            print("‚ùå No se puede generar recomendaci√≥n sin an√°lisis de rendimiento")
            return None
        
        needs_retraining = performance_analysis['needs_retraining']
        priority = needs_retraining['priority']
        
        print(f"üö¶ PRIORIDAD DE REENTRENAMIENTO: {priority}")
        
        if needs_retraining['recommended']:
            print(f"\n‚úÖ SE RECOMIENDA REENTRENAMIENTO")
            print(f"üìã Razones:")
            for reason in needs_retraining['reasons']:
                print(f"   ‚Ä¢ {reason}")
        else:
            print(f"\n‚ùå NO SE REQUIERE REENTRENAMIENTO INMEDIATO")
            print(f"‚úÖ Las mejoras implementadas son suficientes por ahora")
        
        # Plan de acci√≥n espec√≠fico
        action_plan = self._create_specific_action_plan(performance_analysis)
        
        print(f"\nüöÄ PLAN DE ACCI√ìN RECOMENDADO:")
        for phase, actions in action_plan.items():
            print(f"\nüìã {phase}:")
            for i, action in enumerate(actions, 1):
                print(f"   {i}. {action}")
        
        return action_plan
    
    def _create_specific_action_plan(self, analysis):
        """Crea un plan de acci√≥n espec√≠fico"""
        needs_retraining = analysis['needs_retraining']
        problematic_count = len(analysis['problematic_classes'])
        performance_gap = analysis['performance_gap']
        
        if not needs_retraining['recommended']:
            return {
                "FASE 1 - OPTIMIZACI√ìN ACTUAL (0-2 semanas)": [
                    "Optimizar umbrales adaptativos con m√°s datos de validaci√≥n",
                    "Implementar ensemble del modelo actual con diferentes temperaturas",
                    "Aplicar test-time augmentation para mejorar predicciones",
                    "Monitorear rendimiento con m√©tricas por clase detalladas"
                ],
                "FASE 2 - EVALUACI√ìN CONTINUA": [
                    "Recolectar feedback de usuarios reales",
                    "Analizar casos de fallo espec√≠ficos", 
                    "Revisar necesidad de reentrenamiento en 3 meses"
                ]
            }
        elif needs_retraining['priority'] == 'MEDIUM':
            return {
                "FASE 1 - MEJORAS SIN REENTRENAMIENTO (1-2 semanas)": [
                    "Implementar ensemble de modelos existentes",
                    "Aplicar t√©cnicas avanzadas de calibraci√≥n",
                    "Test-time augmentation para clases problem√°ticas",
                    "Optimizaci√≥n de hiperpar√°metros de inferencia"
                ],
                "FASE 2 - FINE-TUNING DIRIGIDO (2-3 semanas)": [
                    f"Fine-tuning solo para las {problematic_count} clases m√°s problem√°ticas",
                    "Aplicar weighted loss espec√≠fico para clases dif√≠ciles",
                    "Data augmentation intensiva para clases problem√°ticas",
                    "Validaci√≥n cruzada para evaluar mejoras"
                ]
            }
        else:  # HIGH priority
            return {
                "FASE 1 - MEJORAS INMEDIATAS (1 semana)": [
                    "Implementar ensemble y TTA para mitigar problemas actuales",
                    "Aplicar rejection sampling para predicciones de baja confianza",
                    "Documentar limitaciones actuales para usuarios"
                ],
                "FASE 2 - REENTRENAMIENTO COMPLETO (3-4 semanas)": [
                    "Recopilar datos adicionales para clases problem√°ticas",
                    "Diversificar dataset geogr√°ficamente",
                    "Entrenar con arquitectura mejorada (EfficientNet-B4 o ViT)",
                    "Implementar t√©cnicas de balanceo avanzadas"
                ],
                "FASE 3 - VALIDACI√ìN Y DESPLIEGUE (1-2 semanas)": [
                    "Evaluaci√≥n exhaustiva del nuevo modelo",
                    "A/B testing contra modelo actual",
                    "Despliegue gradual y monitoreo de rendimiento"
                ]
            }
    
    def estimate_improvement_potential(self, action_plan):
        """Estima el potencial de mejora de cada estrategia"""
        print(f"\nüìà ESTIMACI√ìN DE POTENCIAL DE MEJORA")
        print("="*70)
        
        current_performance = self.class_evaluation.get('overall_accuracy', 0.868)
        
        improvement_estimates = {
            "Optimizaci√≥n actual (sin reentrenamiento)": {
                "accuracy_gain": 0.02,  # +2%
                "time_investment": "1-2 semanas",
                "cost": "Bajo",
                "probability_success": 0.9
            },
            "Fine-tuning dirigido": {
                "accuracy_gain": 0.05,  # +5%
                "time_investment": "2-3 semanas", 
                "cost": "Medio",
                "probability_success": 0.7
            },
            "Reentrenamiento completo": {
                "accuracy_gain": 0.08,  # +8%
                "time_investment": "4-6 semanas",
                "cost": "Alto", 
                "probability_success": 0.6
            }
        }
        
        print(f"üìä RENDIMIENTO ACTUAL: {current_performance:.3f}")
        print(f"\nüéØ ESTIMACIONES DE MEJORA:")
        
        for strategy, estimates in improvement_estimates.items():
            projected_acc = current_performance + estimates['accuracy_gain']
            expected_gain = estimates['accuracy_gain'] * estimates['probability_success']
            
            print(f"\nüìã {strategy}:")
            print(f"   üéØ Ganancia estimada: +{estimates['accuracy_gain']:.3f} ({estimates['accuracy_gain']*100:.1f}%)")
            print(f"   üìà Accuracy proyectada: {projected_acc:.3f}")
            print(f"   üìä Ganancia esperada: +{expected_gain:.3f} ({expected_gain*100:.1f}%)")
            print(f"   ‚è∞ Tiempo: {estimates['time_investment']}")
            print(f"   üí∞ Costo: {estimates['cost']}")
            print(f"   üìà Probabilidad √©xito: {estimates['probability_success']*100:.0f}%")
        
        return improvement_estimates
    
    def create_decision_matrix(self, performance_analysis, improvement_estimates):
        """Crea una matriz de decisi√≥n para ayudar a elegir la mejor estrategia"""
        print(f"\nüìä MATRIZ DE DECISI√ìN")
        print("="*70)
        
        # Crear visualizaci√≥n de la matriz de decisi√≥n
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
        
        # Gr√°fico 1: Ganancia esperada vs Tiempo
        strategies = list(improvement_estimates.keys())
        gains = [est['accuracy_gain'] * est['probability_success'] for est in improvement_estimates.values()]
        times = [1.5, 2.5, 5.0]  # semanas promedio
        costs = ['Bajo', 'Medio', 'Alto']
        colors = ['green', 'orange', 'red']
        
        scatter = ax1.scatter(times, gains, s=200, c=colors, alpha=0.7)
        ax1.set_xlabel('Tiempo de Implementaci√≥n (semanas)')
        ax1.set_ylabel('Ganancia Esperada de Accuracy')
        ax1.set_title('Ganancia Esperada vs Tiempo de Implementaci√≥n')
        ax1.grid(True, alpha=0.3)
        
        # Agregar etiquetas
        for i, (strategy, gain, time) in enumerate(zip(strategies, gains, times)):
            ax1.annotate(strategy.split('(')[0], (time, gain), 
                        xytext=(5, 5), textcoords='offset points', fontsize=9)
        
        # Gr√°fico 2: An√°lisis de clases problem√°ticas
        if self.class_evaluation and 'class_details' in self.class_evaluation:
            class_details = self.class_evaluation['class_details']
            accuracies = [details['accuracy'] for details in class_details.values()]
            
            ax2.hist(accuracies, bins=15, alpha=0.7, color='skyblue', edgecolor='navy')
            ax2.axvline(np.mean(accuracies), color='red', linestyle='--', 
                       label=f'Media: {np.mean(accuracies):.3f}')
            ax2.axvline(0.7, color='orange', linestyle='--', 
                       label='Umbral problem√°tico')
            ax2.set_xlabel('Accuracy por Clase')
            ax2.set_ylabel('N√∫mero de Clases')
            ax2.set_title('Distribuci√≥n de Accuracy por Clase')
            ax2.legend()
        
        plt.tight_layout()
        plt.savefig('retraining_decision_matrix.png', dpi=300, bbox_inches='tight')
        print("   ‚úÖ Matriz de decisi√≥n guardada: retraining_decision_matrix.png")
        
        # Recomendaci√≥n final
        needs_retraining = performance_analysis['needs_retraining']
        
        if needs_retraining['priority'] == 'LOW':
            recommendation = "Optimizaci√≥n actual"
            rationale = "Las mejoras ya implementadas son suficientes. Optimizar sin reentrenamiento."
        elif needs_retraining['priority'] == 'MEDIUM':
            recommendation = "Fine-tuning dirigido" 
            rationale = "Balance √≥ptimo entre mejora esperada y esfuerzo requerido."
        else:
            recommendation = "Reentrenamiento completo"
            rationale = "Los problemas actuales requieren intervenci√≥n fundamental."
        
        print(f"\nüéØ RECOMENDACI√ìN FINAL: {recommendation}")
        print(f"üí° Justificaci√≥n: {rationale}")
        
        return {
            'recommended_strategy': recommendation,
            'rationale': rationale,
            'visualization_path': 'retraining_decision_matrix.png'
        }
    
    def run_complete_analysis(self):
        """Ejecuta el an√°lisis completo de necesidad de reentrenamiento"""
        print("üî¨" * 70)
        print("üî¨ AN√ÅLISIS COMPLETO DE NECESIDAD DE REENTRENAMIENTO")
        print("üî¨" * 70)
        
        # 1. Analizar rendimiento actual
        performance_analysis = self.analyze_current_performance_gaps()
        
        # 2. Categorizar estrategias
        strategies = self.categorize_improvement_strategies()
        
        # 3. Recomendar plan de acci√≥n
        action_plan = self.recommend_action_plan(performance_analysis)
        
        # 4. Estimar potencial de mejora
        improvement_estimates = self.estimate_improvement_potential(action_plan)
        
        # 5. Crear matriz de decisi√≥n
        decision_matrix = self.create_decision_matrix(performance_analysis, improvement_estimates)
        
        # 6. Guardar reporte completo
        complete_report = {
            'timestamp': np.datetime64('now').item().isoformat(),
            'performance_analysis': performance_analysis,
            'improvement_strategies': strategies,
            'action_plan': action_plan,
            'improvement_estimates': improvement_estimates,
            'decision_matrix': decision_matrix
        }
        
        with open('retraining_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(complete_report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\n‚úÖ AN√ÅLISIS COMPLETO FINALIZADO")
        print(f"   üìä Reporte guardado: retraining_analysis_report.json")
        print(f"   üìà Visualizaci√≥n: retraining_decision_matrix.png")
        
        return complete_report

def main():
    """Funci√≥n principal"""
    workspace_path = r"c:\Users\juliy\OneDrive\Escritorio\NOTDOG YESDOG"
    
    analyzer = RetrainingAnalyzer(workspace_path)
    results = analyzer.run_complete_analysis()
    
    return results

if __name__ == "__main__":
    results = main()