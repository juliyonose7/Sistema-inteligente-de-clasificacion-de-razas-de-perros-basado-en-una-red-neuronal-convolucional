"""
Analizador espec√≠fico para las razas de perros y consecuencias de rendimiento
"""

import os
import time
from pathlib import Path
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

class BreedPerformanceAnalyzer:
    def __init__(self, yesdog_path: str, nodog_path: str):
        self.yesdog_path = Path(yesdog_path)
        self.nodog_path = Path(nodog_path)
        self.breed_stats = {}
        
    def analyze_breeds_distribution(self):
        """Analiza la distribuci√≥n de razas y sus implicaciones"""
        print("üîç ANALIZANDO RAZAS DE PERROS...")
        print("="*60)
        
        # Contar im√°genes por raza
        breed_counts = {}
        total_dog_images = 0
        
        for breed_dir in self.yesdog_path.iterdir():
            if breed_dir.is_dir():
                # Contar archivos de imagen
                image_files = [f for f in breed_dir.iterdir() 
                             if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']]
                count = len(image_files)
                breed_counts[breed_dir.name] = count
                total_dog_images += count
        
        # Contar im√°genes NO-DOG
        nodog_images = 0
        for nodog_dir in self.nodog_path.iterdir():
            if nodog_dir.is_dir():
                image_files = [f for f in nodog_dir.iterdir() 
                             if f.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']]
                nodog_images += len(image_files)
        
        print(f"üìä ESTAD√çSTICAS GENERALES:")
        print(f"   üêï Razas de perros: {len(breed_counts)}")
        print(f"   üêï Total im√°genes de perros: {total_dog_images:,}")
        print(f"   ‚ùå Total im√°genes NO-DOG: {nodog_images:,}")
        print(f"   üìà Total clases: {len(breed_counts) + 1} (120 razas + NO-DOG)")
        
        return breed_counts, total_dog_images, nodog_images
    
    def analyze_class_imbalance(self, breed_counts: dict, nodog_images: int):
        """Analiza el desbalanceo de clases"""
        print(f"\n‚öñÔ∏è  AN√ÅLISIS DE DESBALANCEO:")
        print("="*60)
        
        # Agregar NO-DOG como una clase m√°s
        all_counts = breed_counts.copy()
        all_counts['NO-DOG'] = nodog_images
        
        counts = list(all_counts.values())
        class_names = list(all_counts.keys())
        
        # Estad√≠sticas
        min_count = min(counts)
        max_count = max(counts)
        mean_count = np.mean(counts)
        std_count = np.std(counts)
        
        print(f"   üìâ Clase con menos im√°genes: {min_count}")
        print(f"   üìà Clase con m√°s im√°genes: {max_count}")
        print(f"   üìä Promedio por clase: {mean_count:.1f}")
        print(f"   üìè Desviaci√≥n est√°ndar: {std_count:.1f}")
        print(f"   ‚ö†Ô∏è  Ratio max/min: {max_count/min_count:.1f}x")
        
        # Encontrar clases con pocas im√°genes
        low_count_threshold = mean_count * 0.3  # 30% del promedio
        low_count_classes = [(name, count) for name, count in all_counts.items() 
                           if count < low_count_threshold]
        
        if low_count_classes:
            print(f"\n‚ö†Ô∏è  CLASES CON POCAS IM√ÅGENES (< {low_count_threshold:.0f}):")
            for name, count in sorted(low_count_classes, key=lambda x: x[1]):
                print(f"      {name}: {count} im√°genes")
        
        return all_counts, min_count, max_count, mean_count
    
    def estimate_training_performance(self, total_classes: int, total_images: int):
        """Estima las consecuencias de rendimiento del entrenamiento"""
        print(f"\nüöÄ AN√ÅLISIS DE RENDIMIENTO DE ENTRENAMIENTO:")
        print("="*60)
        
        # Comparaci√≥n: Binario vs Multi-clase
        print("üìä COMPARACI√ìN BINARIO vs MULTI-CLASE:")
        print(f"   Modelo actual (binario): 2 clases")
        print(f"   Modelo propuesto: {total_classes} clases")
        print(f"   Factor de complejidad: {total_classes/2:.0f}x")
        
        # Memoria del modelo
        print(f"\nüíæ IMPACTO EN MEMORIA:")
        # Suponiendo EfficientNet-B3
        base_params = 12_000_000  # ~12M par√°metros base
        
        # Capa final para clasificaci√≥n
        binary_final_params = 1536 * 2  # 1536 features ‚Üí 2 clases
        multiclass_final_params = 1536 * total_classes  # 1536 features ‚Üí 121 clases
        
        print(f"   Capa final binaria: {binary_final_params:,} par√°metros")
        print(f"   Capa final multi-clase: {multiclass_final_params:,} par√°metros")
        print(f"   Incremento: {multiclass_final_params - binary_final_params:,} par√°metros")
        print(f"   Incremento memoria: ~{(multiclass_final_params - binary_final_params) * 4 / 1024 / 1024:.1f} MB")
        
        # Tiempo de entrenamiento
        print(f"\n‚è±Ô∏è  TIEMPO DE ENTRENAMIENTO:")
        print(f"   Im√°genes totales: {total_images:,}")
        
        # Estimaciones basadas en experiencia
        base_time_per_epoch = total_images / 1000  # ~1000 im√°genes por minuto
        complexity_factor = 1 + (total_classes - 2) * 0.02  # 2% m√°s tiempo por clase adicional
        
        estimated_time_per_epoch = base_time_per_epoch * complexity_factor
        
        print(f"   Tiempo estimado por √©poca: {estimated_time_per_epoch:.1f} minutos")
        print(f"   Para 30 √©pocas: {estimated_time_per_epoch * 30:.1f} minutos (~{estimated_time_per_epoch * 30 / 60:.1f} horas)")
        
        # Dificultad de convergencia
        print(f"\nüéØ DIFICULTAD DE CONVERGENCIA:")
        if total_classes <= 10:
            difficulty = "F√ÅCIL"
            epochs_needed = "15-25"
        elif total_classes <= 50:
            difficulty = "MODERADO"
            epochs_needed = "25-40"
        elif total_classes <= 100:
            difficulty = "DIF√çCIL"
            epochs_needed = "40-60"
        else:
            difficulty = "MUY DIF√çCIL"
            epochs_needed = "50-80"
            
        print(f"   Dificultad: {difficulty}")
        print(f"   √âpocas recomendadas: {epochs_needed}")
        print(f"   Raz√≥n: Con {total_classes} clases, el modelo necesita aprender")
        print(f"          muchas m√°s caracter√≠sticas distintivas")
        
        return estimated_time_per_epoch, complexity_factor
    
    def recommend_optimization_strategies(self, breed_counts: dict, min_count: int, max_count: int):
        """Recomienda estrategias de optimizaci√≥n"""
        print(f"\nüí° ESTRATEGIAS DE OPTIMIZACI√ìN RECOMENDADAS:")
        print("="*60)
        
        print("1Ô∏è‚É£  ESTRATEGIAS DE DATOS:")
        if max_count / min_count > 10:
            print("   ‚öñÔ∏è  Balanceo agresivo necesario (ratio > 10x)")
            print("      - Undersample clases grandes a max 2000 im√°genes")
            print("      - Oversample clases peque√±as (augmentaci√≥n)")
            print("      - Usar weighted sampling durante entrenamiento")
        else:
            print("   ‚öñÔ∏è  Balanceo moderado suficiente")
            print("      - Weighted loss function")
            print("      - Augmentaci√≥n ligera para clases peque√±as")
        
        print(f"\n2Ô∏è‚É£  ESTRATEGIAS DE MODELO:")
        print("   üß† Transfer Learning OBLIGATORIO")
        print("      - ImageNet pre-entrenado es esencial")
        print("      - Freeze inicial de 10-15 √©pocas")
        print("      - Fine-tuning gradual")
        
        print(f"\n3Ô∏è‚É£  ESTRATEGIAS DE ENTRENAMIENTO:")
        print("   üìà Learning Rate Schedule:")
        print("      - OneCycleLR o CosineAnnealingLR")
        print("      - LR inicial: 1e-4 (m√°s conservador)")
        print("      - Warmup de 5 √©pocas")
        
        print(f"\n4Ô∏è‚É£  ESTRATEGIAS DE HARDWARE:")
        print("   üíª Para AMD 7900XTX:")
        print("      - Batch size: 16-32 (por memoria)")
        print("      - Mixed precision (AMP)")
        print("      - Gradient accumulation si es necesario")
        
        print(f"\n5Ô∏è‚É£  ESTRATEGIAS DE VALIDACI√ìN:")
        print("   üìä M√©tricas espec√≠ficas:")
        print("      - Top-1 y Top-5 accuracy")
        print("      - F1-score por clase")
        print("      - Confusion matrix para clases problem√°ticas")
    
    def create_breed_visualization(self, breed_counts: dict, nodog_images: int):
        """Crea visualizaciones del an√°lisis de razas"""
        print(f"\nüìä CREANDO VISUALIZACIONES...")
        
        # Preparar datos
        all_counts = breed_counts.copy()
        all_counts['NO-DOG'] = nodog_images
        
        # Crear DataFrame
        df = pd.DataFrame(list(all_counts.items()), columns=['Breed', 'Count'])
        df = df.sort_values('Count', ascending=False)
        
        # Crear figura con subplots
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))
        
        # 1. Top 20 razas
        top_20 = df.head(20)
        sns.barplot(data=top_20, x='Count', y='Breed', ax=ax1, palette='viridis')
        ax1.set_title('Top 20 Razas con M√°s Im√°genes', fontsize=14, fontweight='bold')
        ax1.set_xlabel('N√∫mero de Im√°genes')
        
        # 2. Bottom 20 razas (excluyendo NO-DOG)
        bottom_20 = df[df['Breed'] != 'NO-DOG'].tail(20)
        sns.barplot(data=bottom_20, x='Count', y='Breed', ax=ax2, palette='rocket')
        ax2.set_title('Top 20 Razas con Menos Im√°genes', fontsize=14, fontweight='bold')
        ax2.set_xlabel('N√∫mero de Im√°genes')
        
        # 3. Distribuci√≥n de conteos
        ax3.hist(df['Count'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax3.set_title('Distribuci√≥n de Im√°genes por Clase', fontsize=14, fontweight='bold')
        ax3.set_xlabel('N√∫mero de Im√°genes')
        ax3.set_ylabel('N√∫mero de Clases')
        ax3.axvline(df['Count'].mean(), color='red', linestyle='--', label=f'Promedio: {df["Count"].mean():.0f}')
        ax3.legend()
        
        # 4. Estad√≠sticas generales
        ax4.axis('off')
        stats_text = f"""
ESTAD√çSTICAS DEL DATASET

Total de clases: {len(df)}
Total de im√°genes: {df['Count'].sum():,}

Por clase:
‚Ä¢ M√≠nimo: {df['Count'].min()} im√°genes
‚Ä¢ M√°ximo: {df['Count'].max():,} im√°genes  
‚Ä¢ Promedio: {df['Count'].mean():.0f} im√°genes
‚Ä¢ Mediana: {df['Count'].median():.0f} im√°genes

Desbalanceo:
‚Ä¢ Ratio max/min: {df['Count'].max()/df['Count'].min():.1f}x
‚Ä¢ Desv. est√°ndar: {df['Count'].std():.0f}

Clases con < 100 im√°genes: {len(df[df['Count'] < 100])}
Clases con > 1000 im√°genes: {len(df[df['Count'] > 1000])}
        """
        ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=12,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        
        plt.tight_layout()
        plt.savefig('breed_analysis.png', dpi=300, bbox_inches='tight')
        print("   ‚úÖ Guardado: breed_analysis.png")
        
        return df
    
    def run_complete_analysis(self):
        """Ejecuta el an√°lisis completo"""
        start_time = time.time()
        
        print("üêï AN√ÅLISIS COMPLETO DE RAZAS Y RENDIMIENTO")
        print("="*80)
        
        # 1. Analizar distribuci√≥n de razas
        breed_counts, total_dog_images, nodog_images = self.analyze_breeds_distribution()
        
        # 2. Analizar desbalanceo
        all_counts, min_count, max_count, mean_count = self.analyze_class_imbalance(
            breed_counts, nodog_images
        )
        
        # 3. Estimar rendimiento
        total_classes = len(breed_counts) + 1
        total_images = total_dog_images + nodog_images
        time_per_epoch, complexity_factor = self.estimate_training_performance(
            total_classes, total_images
        )
        
        # 4. Recomendar optimizaciones
        self.recommend_optimization_strategies(breed_counts, min_count, max_count)
        
        # 5. Crear visualizaciones
        df = self.create_breed_visualization(breed_counts, nodog_images)
        
        # Resumen final
        elapsed_time = time.time() - start_time
        print(f"\nüéØ RESUMEN EJECUTIVO:")
        print("="*60)
        print(f"‚úÖ Factibilidad del proyecto: ALTA")
        print(f"‚ö†Ô∏è  Complejidad: ALTA (121 clases)")
        print(f"‚è±Ô∏è  Tiempo estimado de entrenamiento: {time_per_epoch * 50:.0f} minutos")
        print(f"üíæ Memoria adicional requerida: ~{(121-2) * 1536 * 4 / 1024 / 1024:.1f} MB")
        print(f"üéØ Accuracy esperada: 75-85% (top-1), 90-95% (top-5)")
        
        print(f"\nüìã RECOMENDACI√ìN:")
        if max_count / min_count > 20:
            print("   üî¥ PRECAUCI√ìN: Desbalanceo muy alto")
            print("   üëâ Implementar balanceo agresivo antes de entrenar")
        elif total_classes > 100:
            print("   üü° COMPLEJIDAD ALTA pero manejable")
            print("   üëâ Usar transfer learning + estrategias de optimizaci√≥n")
        else:
            print("   üü¢ FACTIBLE con estrategias est√°ndar")
        
        print(f"\n‚è±Ô∏è  An√°lisis completado en {elapsed_time:.1f} segundos")
        
        return {
            'breed_counts': breed_counts,
            'total_classes': total_classes,
            'total_images': total_images,
            'time_per_epoch': time_per_epoch,
            'complexity_factor': complexity_factor,
            'imbalance_ratio': max_count / min_count,
            'dataframe': df
        }

def main():
    """Funci√≥n principal para ejecutar el an√°lisis"""
    yesdog_path = r"c:\Users\juliy\OneDrive\Escritorio\NOTDOG YESDOG\DATASETS\YESDOG"
    nodog_path = r"c:\Users\juliy\OneDrive\Escritorio\NOTDOG YESDOG\DATASETS\NODOG"
    
    analyzer = BreedPerformanceAnalyzer(yesdog_path, nodog_path)
    results = analyzer.run_complete_analysis()
    
    return results

if __name__ == "__main__":
    results = main()